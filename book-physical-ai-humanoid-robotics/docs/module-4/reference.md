---
title: "VLA Terminology Reference"
sidebar_label: "Terminology"
description: "Reference page for Vision-Language-Action (VLA) terminology"
slug: "/module-4/terminology"
---

# VLA Terminology Reference

This page provides definitions for key terms used in the Vision-Language-Action (VLA) module.

## Key Terms

### Vision-Language-Action (VLA)
A system architecture that integrates visual perception, natural language processing, and robotic action capabilities to enable intelligent robot behavior.

### Vision Component
The perception system that processes visual information from cameras and sensors to understand the environment.

### Language Component
The natural language processing system that interprets commands and generates plans for robot actions.

### Action Component
The robotic control system that executes physical movements and manipulations in the environment.

### Speech Recognition
The process of converting spoken language into text that can be processed by language models.

### Intent Mapping
The process of translating natural language commands into specific robot actions or behaviors.

### Cognitive Planning
The use of large language models to generate high-level task plans from natural language commands.

### Reasoning Loop
A feedback mechanism that allows the system to assess its progress and adjust its plans as needed.

### ROS 2 Actions
A communication pattern in ROS 2 for executing long-running tasks with feedback and goal management.

### OpenAI Whisper
An automatic speech recognition (ASR) system that converts speech to text.

### Latency
The time delay between a command being issued and the system's response.

### Accuracy
The correctness of the system's interpretation of commands and execution of actions.